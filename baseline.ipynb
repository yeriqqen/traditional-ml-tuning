{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":103219,"databundleVersionId":12462890,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Baseline Model Evolution Report\n\n### Initial Version for Submission (v2.0) - Enhanced Baseline\n\n#### Data Processing Improvements\n**Added:** Manual missing value handling with median imputation\n- Replaced basic fillna() with manual median calculation and storage\n- Ensures consistent preprocessing between train and test data\n- `col_medians = []` list to store training medians for test preprocessing\n\n**Added:** Feature selection pipeline\n- `remove_correlated_features()` function to eliminate highly correlated features (>0.9 threshold)\n- Reduces multicollinearity and potential overfitting\n- Dynamic feature removal based on correlation matrix\n\n**Added:** Manual Min-Max scaling implementation\n- `manual_minmax_scale()` function replacing sklearn dependency\n- Stores min/max values for consistent test data transformation\n- Handles edge cases (division by zero when min equals max)\n\n#### Model Architecture Enhancements\n**Improved:** SVM Implementation (`ImprovedSVM` class)\n- Enhanced convergence checking with cost threshold\n- Better gradient calculation handling for single samples\n- Improved weight initialization and training stability\n- Added proper label conversion to {-1, +1} for SVM\n\n**Added:** Logistic Regression Implementation\n- Custom `LogisticRegression` class with sigmoid activation\n- Gradient descent optimization with clipping to prevent overflow\n- Regularization through proper weight initialization\n- Progress monitoring during training\n\n**Added:** Ensemble Model\n- `EnsembleModel` class combining SVM and Logistic Regression\n- Majority voting mechanism for final predictions\n- Leverages strengths of both model types\n\n#### Training and Evaluation Improvements\n**Added:** Model comparison framework\n- Dictionary-based model storage for easy iteration\n- Automatic best model selection based on validation accuracy\n- Comprehensive accuracy reporting for all models\n\n**Enhanced:** Hyperparameter considerations\n- Configurable learning rates and regularization strengths\n- Maximum iteration limits with early stopping\n- Model-specific parameter tuning\n\n#### Test Data Processing\n**Improved:** Consistent preprocessing pipeline\n- Applies same median imputation as training data\n- Removes identical correlated features\n- Applies identical scaling transformation\n- Maintains feature alignment between train and test\n\n#### Code Quality Improvements\n**Added:** Better error handling and edge case management\n- Numpy array shape consistency checks\n- Overflow prevention in sigmoid calculations\n- Robust gradient calculations\n\n**Enhanced:** Documentation and logging\n- Progress printing during model training\n- Clear model performance reporting\n- Step-by-step processing feedback\n\n### Performance Impact\n- **Baseline accuracy:** ~54.6% (estimated initial performance)\n- **Current best model:** 56.1% (Logistic Regression)\n- **Ensemble model:** 52.2% (showing potential for further tuning)\n\n### Key Technical Decisions\n1. **Manual implementations** over sklearn to maintain full control and understanding\n2. **Feature selection** to reduce dimensionality and improve generalization\n3. **Ensemble approach** to combine different model strengths\n4. **Consistent preprocessing** to ensure train/test data alignment\n\n### Future Improvement Opportunities\n- Hyperparameter optimization (grid search, random search)\n- Additional feature engineering techniques\n- More sophisticated ensemble methods (weighted voting, stacking)\n- Cross-validation for more robust model selection\n- Advanced regularization techniques\n\n### Dependencies Managed\n- Minimal external dependencies (numpy, pandas)\n- Custom implementations for core ML algorithms\n- Reproducible preprocessing pipeline\n\n---\n\n### Version 2.1 - Advanced Preprocessing and Model Tuning\n\n#### Reasoning and Methods\nTo address the limitations of the initial preprocessing pipeline, advanced techniques were introduced to better handle feature scaling and non-linear relationships. Standardization (z-score) was implemented to ensure features had zero mean and unit variance, improving model convergence. Polynomial feature expansion (degree 2) was added to capture non-linear interactions, and log transformations were applied to reduce the impact of skewed features and outliers.\n\n#### Expectations\nThese enhancements were expected to improve the performance of models sensitive to feature scaling and non-linearities, such as Logistic Regression and SVM.\n\n#### Outcomes\n- Logistic Regression achieved 57.3% validation accuracy, demonstrating improved performance with standardized and polynomially expanded features.\n- SVM achieved 54.6% validation accuracy, benefiting from log-transformed features and z-score normalization.\n- Ensemble model achieved 53.1% validation accuracy, highlighting the potential of combining multiple models for robustness.\n\n#### Reflections\nThe introduction of advanced preprocessing techniques led to noticeable performance improvements. Logistic Regression emerged as the best-performing model in this version, validating the importance of feature scaling and transformation.\n\n---\n\n### Version 3.0 - Comprehensive ML Pipeline\n\n#### Reasoning and Methods\nThis version focused on creating a comprehensive pipeline with advanced feature engineering and systematic hyperparameter tuning. Interaction terms, binning, and k-means clustering were introduced to capture complex relationships. Power transforms (sqrt, square) were applied to enhance feature distributions, and low variance feature removal was used to reduce noise.\n\n#### Expectations\nThese methods were expected to improve model interpretability and performance by creating more informative features and reducing noise.\n\n#### Outcomes\n- Logistic Regression with L2 regularization showed enhanced generalization and reduced overfitting.\n- RBF SVM achieved faster training and improved accuracy.\n- Weighted voting in ensemble methods combined model predictions effectively, boosting overall performance.\n\n#### Reflections\nThe systematic approach to feature engineering and hyperparameter tuning significantly boosted model performance. The pipeline demonstrated the importance of preprocessing variants and model selection.\n\n---\n\n### Version 4.0 - PRBF Hybrid Kernel SVM\n\n#### Reasoning and Methods\nA novel PRBF (Polynomial-RBF) hybrid kernel SVM was implemented to combine the strengths of RBF and Polynomial kernels. The hybrid kernel formula allowed for a tunable mixing ratio, providing flexibility in capturing complex patterns.\n\n#### Expectations\nThe hybrid kernel was expected to outperform individual kernels by leveraging their complementary strengths.\n\n#### Outcomes\n- Achieved 71% validation accuracy, demonstrating the effectiveness of hybrid kernels.\n- Highlighted the potential of combining kernel methods for complex datasets.\n\n#### Reflections\nThe PRBF hybrid kernel validated the hypothesis that combining kernels can enhance model performance. However, the complexity of tuning multiple parameters posed challenges.\n\n---\n\n### Version 5.0 - RandomForest and PRBF Hybrid\n\n#### Reasoning and Methods\nThis version introduced a custom RandomForest with early stopping and OOB validation. Bootstrap sampling and feature subsampling were used to reduce variance, while early stopping prevented overfitting. The PRBF Kernel SVM was further optimized for better performance.\n\n#### Expectations\nRandomForest was expected to provide robust performance due to its ensemble nature, while the optimized PRBF Kernel SVM aimed to improve accuracy further.\n\n#### Outcomes\n- RandomForest achieved 74.75% validation accuracy, outperforming other models.\n- PRBF Kernel SVM showed marginal improvements but was overshadowed by RandomForest.\n\n#### Reflections\nRandomForest emerged as the primary focus due to its superior performance and robustness. The ensemble approach proved effective in handling complex datasets.\n\n---\n\n### Version 6.0 - Optimized RandomForest\n\n#### Reasoning and Methods\nUnderperforming models with accuracy below 72% were removed to streamline the implementation. The focus shifted entirely to optimizing RandomForest, with enhanced preprocessing tailored to its strengths.\n\n#### Expectations\nBy concentrating on a single high-performing model, further improvements in accuracy and efficiency were anticipated.\n\n#### Outcomes\n- RandomForest achieved 74.75% validation accuracy, maintaining its position as the leading model.\n\n#### Reflections\nThe decision to focus on RandomForest simplified the implementation and improved performance. This version highlighted the importance of prioritizing high-performing models.\n\n---\n\n### Version 7.0 - Enhanced RandomForest\n\n#### Reasoning and Methods\nAdvanced features were added to RandomForest, including OOB validation, early stopping, and improved feature subsampling. These enhancements aimed to further boost accuracy and reduce overfitting.\n\n#### Expectations\nThe enhanced RandomForest was expected to achieve the highest accuracy in the project, solidifying its position as the champion model.\n\n#### Outcomes\n- Achieved 76.25% validation accuracy, marking the highest performance in the project.\n\n#### Reflections\nThe enhanced RandomForest validated the effectiveness of ensemble methods and advanced features. This version finalized the model as production-ready, achieving significant accuracy improvements.\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Load dataset\ndf = pd.read_csv('/kaggle/input/mldl-2025/train.csv')\nif 'ID' in df.columns:\n    df = df.drop(columns=['ID'])\n\nX = df.drop(columns=['Y'])\ny = df['Y'].values\n\n# Handle missing values with median\ncol_medians = []\nfor col in X.columns:\n    median = X[col].median()\n    col_medians.append(median)\n    X[col] = X[col].fillna(median)\n\ndef remove_correlated_features(X):\n    corr = X.corr()\n    drop_columns = []\n    for i in range(len(corr.columns)):\n        for j in range(i + 1, len(corr.columns)):\n            if abs(corr.iloc[i, j]) >= 0.85:  \n                drop_columns.append(corr.columns[j])\n    drop_columns = list(set(drop_columns))\n    X.drop(drop_columns, axis=1, inplace=True)\n    return drop_columns\n\ndef manual_standardize(X):\n    X_std = X.copy()\n    means = X.mean()\n    stds = X.std()\n    for col in X.columns:\n        if stds[col] != 0:\n            X_std[col] = (X[col] - means[col]) / stds[col]\n        else:\n            X_std[col] = 0\n    return X_std, means, stds\n\ndef polynomial_features(X):\n    X_poly = X.copy()\n    cols = X.columns\n    new_features = {}\n    for i in range(len(cols)):\n        for j in range(i, len(cols)):\n            new_col = f\"{cols[i]}*{cols[j]}\"\n            new_features[new_col] = X[cols[i]] * X[cols[j]]\n    X_poly = pd.concat([X_poly, pd.DataFrame(new_features, index=X.index)], axis=1)\n    return X_poly\n\ndef remove_low_variance_features(X, threshold=0.005): \n    variances = X.var()\n    low_var_cols = variances[variances < threshold].index\n    return X.drop(columns=low_var_cols), low_var_cols\n\n# Feature selection\ncorr_dropped = remove_correlated_features(X)\nX, low_var_dropped = remove_low_variance_features(X)\n\n# Best preprocessing: polynomial + standardization\nX_poly = polynomial_features(X)\nX_poly_std, X_poly_means, X_poly_stds = manual_standardize(X_poly)\nX_poly_std = pd.concat([X_poly_std, pd.DataFrame({'intercept': 1}, index=X_poly_std.index)], axis=1)\n\n# Train/test split\nX_train, X_val, y_train, y_val = train_test_split(X_poly_std.values, y, test_size=0.25, random_state=42)","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Enhanced RandomForest implementation with OOB validation and early stopping\nclass Model:\n    def __init__(self):\n        self.n_estimators = 250          \n        self.max_depth = 15             \n        self.min_samples_split = 5      \n        self.min_samples_leaf = 3       \n        self.max_features = 'log2'      \n        self.bootstrap = True\n        self.trees = []\n        self.oob_indices = []\n        self.patience = 15              \n        self.best_oob = -1\n        self.no_improve = 0\n\n    def _gini_impurity(self, y):\n        if len(y) == 0:\n            return 0\n        p = np.sum(y == 1) / len(y)\n        return 2 * p * (1 - p)\n\n    def _information_gain(self, y, left_y, right_y):\n        n = len(y)\n        if n == 0:\n            return 0\n        n_left = len(left_y)\n        n_right = len(right_y)\n        \n        parent_gini = self._gini_impurity(y)\n        left_gini = self._gini_impurity(left_y)\n        right_gini = self._gini_impurity(right_y)\n        \n        weighted_gini = (n_left / n) * left_gini + (n_right / n) * right_gini\n        return parent_gini - weighted_gini\n\n    def _build_tree(self, X, y, depth=0):\n        n_samples, n_features = X.shape\n        \n        if (depth >= self.max_depth or\n            n_samples < self.min_samples_split or\n            len(np.unique(y)) == 1):\n            return {'leaf': True, 'prediction': np.round(np.mean(y))}\n        \n        # Feature selection method\n        if self.max_features == 'sqrt':\n            max_features = int(np.sqrt(n_features))\n        elif self.max_features == 'log2':\n            max_features = max(1, int(np.log2(n_features)))\n        else:\n            max_features = n_features\n        \n        feature_indices = np.random.choice(n_features, max_features, replace=False)\n        \n        best_gain = -1\n        best_feature = None\n        best_threshold = None\n        \n        for feature_idx in feature_indices:\n            thresholds = np.percentile(X[:, feature_idx], [20, 35, 50, 65, 80]) \n            \n            for threshold in thresholds:\n                left_mask = X[:, feature_idx] <= threshold\n                right_mask = ~left_mask\n                \n                if (np.sum(left_mask) < self.min_samples_leaf or \n                    np.sum(right_mask) < self.min_samples_leaf):\n                    continue\n                \n                gain = self._information_gain(y, y[left_mask], y[right_mask])\n                \n                if gain > best_gain:\n                    best_gain = gain\n                    best_feature = feature_idx\n                    best_threshold = threshold\n        \n        if best_feature is None:\n            return {'leaf': True, 'prediction': np.round(np.mean(y))}\n        \n        left_mask = X[:, best_feature] <= best_threshold\n        right_mask = ~left_mask\n        \n        left_tree = self._build_tree(X[left_mask], y[left_mask], depth + 1)\n        right_tree = self._build_tree(X[right_mask], y[right_mask], depth + 1)\n        \n        return {\n            'leaf': False,\n            'feature': best_feature,\n            'threshold': best_threshold,\n            'left': left_tree,\n            'right': right_tree\n        }\n\n    def _predict_tree(self, tree, X):\n        if tree['leaf']:\n            return np.full(len(X), tree['prediction'])\n        \n        predictions = np.zeros(len(X))\n        left_mask = X[:, tree['feature']] <= tree['threshold']\n        right_mask = ~left_mask\n        \n        if np.sum(left_mask) > 0:\n            predictions[left_mask] = self._predict_tree(tree['left'], X[left_mask])\n        if np.sum(right_mask) > 0:\n            predictions[right_mask] = self._predict_tree(tree['right'], X[right_mask])\n        \n        return predictions\n\n    def fit(self, X, y):\n        n_samples = X.shape[0]\n        print(f\"- n_estimators: {self.n_estimators}\")\n        print(f\"- max_depth: {self.max_depth}\")\n        print(f\"- min_samples_split: {self.min_samples_split}\")\n        print(f\"- min_samples_leaf: {self.min_samples_leaf}\")\n        print(f\"- max_features: {self.max_features}\")\n        print(f\"- patience: {self.patience}\")\n        \n        for i in range(self.n_estimators):\n            if self.bootstrap:\n                indices = np.random.choice(n_samples, n_samples, replace=True)\n                X_bootstrap = X[indices]\n                y_bootstrap = y[indices]\n                oob_idx = np.setdiff1d(np.arange(n_samples), indices)\n                self.oob_indices.append(oob_idx)\n            else:\n                X_bootstrap = X\n                y_bootstrap = y\n                self.oob_indices.append(np.arange(n_samples))\n            \n            tree = self._build_tree(X_bootstrap, y_bootstrap)\n            self.trees.append(tree)\n            \n            # heck OOB every 5 trees\n            if (i + 1) % 5 == 0:\n                oob_pred = self._get_oob_predictions(X, i + 1)\n                oob_acc = np.mean(oob_pred == y)\n                print(f\"[{i + 1:3d}] OOB Accuracy: {oob_acc*100:.2f}%\")\n                \n                if oob_acc > self.best_oob + 1e-6:\n                    self.best_oob = oob_acc\n                    self.no_improve = 0\n                else:\n                    self.no_improve += 1\n                \n                if self.no_improve >= self.patience:\n                    print(f\"Early stopping at tree {i + 1}\")\n                    break\n\n    def _get_oob_predictions(self, X, n_trees):\n        n_samples = X.shape[0]\n        oob_votes = np.zeros(n_samples)\n        oob_counts = np.zeros(n_samples)\n        \n        for t in range(n_trees):\n            idx = self.oob_indices[t]\n            if idx.size == 0:\n                continue\n            \n            preds = self._predict_tree(self.trees[t], X[idx])\n            oob_votes[idx] += preds\n            oob_counts[idx] += 1\n        \n        mask = oob_counts > 0\n        oob_final = np.zeros(n_samples, dtype=int)\n        oob_final[mask] = (oob_votes[mask] / oob_counts[mask] > 0.5).astype(int)\n        \n        return oob_final\n\n    def predict_proba(self, X):\n        n_samples = X.shape[0]\n        predictions = np.zeros(n_samples)\n        \n        for tree in self.trees:\n            predictions += self._predict_tree(tree, X)\n        \n        return predictions / len(self.trees)\n\n    def predict(self, X):\n        return (self.predict_proba(X) > 0.5).astype(int)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train model\nmodel = Model()\nmodel.fit(X_train, y_train)\npreds = model.predict(X_val)\naccuracy = np.mean(preds == y_val)\nprint(f\"\\nFinal Validation Accuracy: {accuracy*100:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load and preprocess test data\ntest_df = pd.read_csv('/kaggle/input/mldl-2025/test.csv')\ntest_ids = test_df.index\n\nX_test = test_df.copy()\n\n# Handle missing values using training medians\nfor i, col in enumerate(X_test.columns):\n    X_test[col] = X_test[col].fillna(col_medians[i])\n\n# Remove same features as training\nX_test.drop(corr_dropped, axis=1, inplace=True, errors='ignore')\nX_test.drop(low_var_dropped, axis=1, inplace=True, errors='ignore')\n\n# Apply polynomial features then standardize\nX_test_transformed = polynomial_features(X_test)\nfor col in X_poly_means.index:\n    if col in X_test_transformed.columns:\n        if X_poly_stds[col] != 0:\n            X_test_transformed[col] = (X_test_transformed[col] - X_poly_means[col]) / X_poly_stds[col]\n        else:\n            X_test_transformed[col] = 0\n\nX_test_transformed = pd.concat([X_test_transformed, pd.DataFrame({'intercept': 1}, index=X_test_transformed.index)], axis=1)\n\n# Generate predictions\npreds = model.predict(X_test_transformed.values)\n\n# Save submission\nsubmission_df = pd.DataFrame({\n    'ID': test_ids,\n    'Potability': preds\n})\nsubmission_df.to_csv('submission.csv', index=False)\nprint(\"Predictions saved to submission.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}